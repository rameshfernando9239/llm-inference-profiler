# llm-inference-profiler
LLM Inference Latency Profiler for edge case scenarios - Supports OPT-1.3B, Phi-2B, Llama-2-7B, Llama-2-13B, Llama-3-8B with AWQ and BitsAndBytes quantization
